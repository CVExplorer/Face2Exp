{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb2da06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import argparse\n",
    "import logging\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.cuda import amp\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch import optim\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm.notebook import tqdm as tqdm\n",
    "# from tqdm import tqdm_notebook as tqdm\n",
    "import torchvision.models\n",
    "import torch.nn as nn\n",
    "\n",
    "from torchvision import transforms\n",
    "import torch.utils.data as data\n",
    "\n",
    "from augmentation2 import RandAugment\n",
    "\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "from data_baseline import DATASET_GETTERS\n",
    "from models import WideResNet, ModelEMA, RestNet18\n",
    "from utils import (AverageMeter, accuracy, create_loss_fn,\n",
    "                   save_checkpoint, reduce_tensor, model_load_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35b50898",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'\n",
    "seed = 5\n",
    "num_classes = 8\n",
    "total_steps = 10000\n",
    "eval_step = 100\n",
    "batch_size = 32\n",
    "teacher_lr = 1e-3\n",
    "student_lr = 1e-3\n",
    "label_smoothing = 0.1\n",
    "lambda_u = 8 \n",
    "warmup_steps = 0\n",
    "uda_steps = 10000\n",
    "student_wait_steps = 0\n",
    "resize = 224\n",
    "workers = 16\n",
    "best_top1 = 0\n",
    "best_top2 = 0\n",
    "mu = 1\n",
    "ema = 0.995\n",
    "batch_size = 32\n",
    "gpu = 0\n",
    "device = torch.device('cuda', gpu)\n",
    "momentum = 0.9\n",
    "nesterov = True\n",
    "threshold = 0.6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45679d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_name = '../../Face2Exp/src/experiment_basic_1637393663/try_best.pth.tar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "986c98bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_val = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5863, 0.4595, 0.4030), std=(0.2715, 0.2424, 0.2366))\n",
    "])\n",
    "\n",
    "orginal_dataset_dir = '/home/data/lzy/AffectNet/Manually_Annotated/Manually_Annotated_Images/'\n",
    "path_meta_val = '/home/data/lzy/AffectNet/Manually_Annotated_file_lists/validation.csv'\n",
    "DF2 = pd.read_csv(path_meta_val)\n",
    "DFselect2 = DF2.loc[DF2['expression'] <7]\n",
    "\n",
    "\n",
    "class AfData(data.Dataset):\n",
    "    def __init__(self,data,directory,transform):\n",
    "        self.data = data\n",
    "        self.directory = directory\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self,idx):\n",
    "        path = os.path.join(self.directory, self.data.iloc[idx]['subDirectory_filePath'])\n",
    "        x,y,w,h = self.data.iloc[idx]['face_x'],self.data.iloc[idx]['face_y'],self.data.iloc[idx]['face_width'],self.data.iloc[idx]['face_height']\n",
    "        target = self.data.iloc[idx]['expression']\n",
    "        image = Image.open(path).convert('RGB')\n",
    "        #image = cv2.imread(path, cv2.COLOR_BGR2RGB)\n",
    "        cropped = image.crop((x, y, x+w, y+h))\n",
    "        img = self.transform(cropped)\n",
    "        return img, target\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4058612",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_loss_fn():\n",
    "    if label_smoothing > 0:\n",
    "        criterion = SmoothCrossEntropy(alpha=label_smoothing)\n",
    "    else:\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "    return criterion.to(device)\n",
    "\n",
    "class SmoothCrossEntropy(nn.Module):\n",
    "    def __init__(self, alpha=0.1):\n",
    "        super(SmoothCrossEntropy, self).__init__()\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def forward(self, logits, labels):\n",
    "        num_classes = logits.shape[-1]\n",
    "        alpha_div_k = self.alpha / num_classes\n",
    "        target_probs = F.one_hot(labels, num_classes=num_classes).float() * \\\n",
    "            (1. - self.alpha) + alpha_div_k\n",
    "        loss = -(target_probs * torch.log_softmax(logits, dim=-1)).sum(dim=-1)\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecaef0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda', gpu)\n",
    "model = torchvision.models.resnet50(pretrained=False)\n",
    "model.fc = nn.Linear(2048, 7)\n",
    "model.cuda()\n",
    "model = model.to(device)\n",
    "\n",
    "loc = f'cuda:{gpu}'\n",
    "\n",
    "state_dict = torch.load(ckpt_name, map_location=loc)\n",
    "model.load_state_dict(state_dict['student_state_dict'])\n",
    "\n",
    "test_dataset = AfData(data=DFselect2, directory=orginal_dataset_dir, transform=transform_val)\n",
    "train_dataset = AfData(data=DFselect2, directory=orginal_dataset_dir, transform=transform_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de8b422b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f210b8336894bbfbdb479e0998af047",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/110 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_time = AverageMeter()\n",
    "data_time = AverageMeter()\n",
    "losses = AverageMeter()\n",
    "top1 = AverageMeter()\n",
    "top2 = AverageMeter()\n",
    "model.eval()\n",
    "\n",
    "train_sampler = RandomSampler\n",
    "\n",
    "test_loader = DataLoader(test_dataset,\n",
    "                         sampler=SequentialSampler(test_dataset),\n",
    "                         batch_size=batch_size,\n",
    "                         num_workers=workers,\n",
    "                         pin_memory=True\n",
    "                         )\n",
    "\n",
    "train_loader = DataLoader(train_dataset,\n",
    "        sampler=train_sampler(train_dataset),\n",
    "        batch_size=batch_size * mu,\n",
    "        num_workers=workers,\n",
    "        pin_memory=True)\n",
    "\n",
    "test_iter = tqdm(test_loader, disable=False)\n",
    "\n",
    "criterion = create_loss_fn()\n",
    "\n",
    "with torch.no_grad():\n",
    "    end = time.time()\n",
    "    for step, (images, targets) in enumerate(test_iter):\n",
    "        data_time.update(time.time() - end)\n",
    "        batch_size = targets.shape[0]\n",
    "        images = images.to(device)\n",
    "        targets = targets.to(device)\n",
    "        with amp.autocast(enabled=True):\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "        acc1, acc2 = accuracy(outputs, targets, (1, 2))\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        top1.update(acc1[0], batch_size)\n",
    "        top2.update(acc2[0], batch_size)\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        test_iter.set_description(\n",
    "            f\"Test Iter: {step + 1:3}/{len(test_loader):3}.  \"\n",
    "            f\"Loss: {losses.avg:.4f}. \"\n",
    "            f\"top1: {top1.avg:.2f}. top2: {top2.avg:.2f}. \")\n",
    "\n",
    "    test_iter.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50852d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lin",
   "language": "python",
   "name": "lin"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
